# â˜• Sentiment Analysis: Coffee Shop Reviews
## Indonesian Coffee Chain Reviews Classification using Machine Learning

<div align="center">

![License](https://img.shields.io/badge/License-MIT-blue.svg?style=flat-square)
![Python](https://img.shields.io/badge/Python-3.11+-green.svg?style=flat-square)
![Status](https://img.shields.io/badge/Status-Active-brightgreen.svg?style=flat-square)
![Models](https://img.shields.io/badge/ML%20Models-6-orange.svg?style=flat-square)
![Accuracy](https://img.shields.io/badge/Best%20Accuracy-88.96%25-success.svg?style=flat-square)
![Datasets](https://img.shields.io/badge/Brands%20Analyzed-3-blue.svg?style=flat-square)

**Advanced NLP & Machine Learning | Streamlit Dashboard | Production-Ready**

[ğŸ”— Live Dashboard](#-deployment) â€¢ [ğŸ“Š Documentation](#-table-of-contents) â€¢ [ğŸš€ Quick Start](#-quick-start) â€¢ [ğŸ“ˆ Results](#-model-performance)

</div>

---

## ğŸ“‹ Table of Contents

| Section | Link |
|---------|------|
| ğŸ¯ Overview | [View](#-overview) |
| ğŸ“Š Dataset | [View](#-dataset-description) |
| ğŸ“ Structure | [View](#-project-structure) |
| ğŸš€ Quick Start | [View](#-quick-start) |
| âš™ï¸ Installation | [View](#-installation--setup) |
| ğŸ’» Usage | [View](#-usage) |
| ğŸ“ˆ Results | [View](#-model-performance) |
| â˜• Per-Brand Analysis | [View](#-per-brand-analysis--metrics) |
| ğŸ” Key Findings | [View](#-key-findings) |
| ğŸ“Š Metrics Explained | [View](#-evaluation-metrics-explained) |
| ğŸ“ Output Files | [View](#-output-files) |
| ğŸ”§ Deployment | [View](#-deployment) |
| ğŸ“‹ Requirements | [View](#-requirements) |

---

## ğŸ¯ Overview

This project implements a **comprehensive sentiment analysis system** for Indonesian coffee shop reviews from **3 major brands**:
- â˜• **Kopi Nako** (1,000 reviews)
- â˜• **Starbucks** (583 reviews)  
- â˜• **Kopi Kenangan** (1,451 reviews)

The system uses **6 machine learning algorithms** to classify customer reviews as **positive** or **negative** sentiment with **88.96% accuracy**.

### ğŸ“ What You'll Learn
- âœ¨ Text preprocessing & NLP for Indonesian language
- ğŸ¤– Train & evaluate 6 different ML models
- ğŸ“Š Comprehensive evaluation metrics (Accuracy, Precision, Recall, F1, AUC-ROC, Confusion Matrix)
- ğŸ¨ Professional data visualization with Matplotlib & Seaborn
- ğŸš€ Deploy interactive dashboard with Streamlit
- ğŸ“ˆ Per-brand sentiment analysis & model comparison  

---

## ï¿½ Quick Start

### Option 1: Run Locally (2 minutes)
```bash
# 1. Clone repository
cd d:\skripsi angel

# 2. Activate virtual environment
.\venv\Scripts\Activate.ps1

# 3. Install dependencies
pip install -r requirements.txt

# 4. Run analysis
python sentiment_analysis.py

# 5. View results (PNG files generated automatically)
```

### Option 2: Deploy to Streamlit Cloud (3 minutes)
```bash
# Go to https://streamlit.io/cloud
# Sign in with GitHub
# Deploy: SeedFlora/sentimentAnalysisCoffeeShop â†’ main â†’ streamlit_app.py
# Access: https://sentimentanalysiscoffeeshop.streamlit.app
```

---

## ğŸ“Š Dataset Description

### ğŸ“ˆ Dataset Overview
| Brand | Reviews | Class Balance | Language |
|-------|---------|---|----------|
| **Kopi Nako** | 1,000 | 88% Pos / 12% Neg | Indonesian |
| **Starbucks** | 583 | 82% Pos / 18% Neg | Indonesian |
| **Kopi Kenangan** | 1,451 | 85% Pos / 15% Neg | Indonesian |
| **TOTAL COMBINED** | **3,034** | **86% Pos / 14% Neg** | **Indonesian** |

### Available Columns:
- **title**: Review title
- **text**: Full review text (PRIMARY FEATURE)
- **sentiment**: Ground truth label (positive/negative)
- **stars**: Review rating (1-5)
- **taste**, **service**, **ambience**, **price**, **packaging**: Feature ratings

---

## ğŸ“ Project Structure

```
d:\skripsi angel/
â”œâ”€â”€ venv/                                  # Virtual environment
â”œâ”€â”€ kopinako_main_analysis.csv            # Kopi Nako reviews dataset
â”œâ”€â”€ starbucks_detailed_reviews.csv        # Starbucks reviews dataset
â”œâ”€â”€ Kopi_Kenangan.xlsx                    # Kopi Kenangan reviews dataset
â”‚
â”œâ”€â”€ PYTHON SCRIPTS:
â”œâ”€â”€ sentiment_analysis.py                 # Combined analysis (Kopi Nako + Starbucks)
â”œâ”€â”€ per_brand_analysis.py                 # Per-brand balancing analysis
â”œâ”€â”€ per_brand_model_evaluation.py         # Per-brand model evaluation
â”œâ”€â”€ explore_csvs.py                       # Data exploration script
â”‚
â”œâ”€â”€ OUTPUT FILES - COMBINED ANALYSIS:
â”œâ”€â”€ model_performance_results.csv         # Model performance comparison
â”œâ”€â”€ model_comparison.png                  # Performance visualization
â”œâ”€â”€ roc_curve.png                        # ROC curve for best model
â”œâ”€â”€ sentiment_distribution.png            # Sentiment distribution charts
â”œâ”€â”€ feature_importance_rf.png             # Random Forest top features
â”œâ”€â”€ feature_importance_lr.png             # Logistic Regression coefficients
â”‚
â”œâ”€â”€ OUTPUT FILES - PER-BRAND ANALYSIS:
â”œâ”€â”€ per_brand_evaluation_results.csv      # Per-brand metrics (Accuracy, Precision, Recall, F1, AUC)
â”œâ”€â”€ per_brand_metrics_comparison.png      # Per-brand metrics visualization
â”œâ”€â”€ per_brand_models_comparison.png       # All 6 models comparison per brand
â”œâ”€â”€ per_brand_metrics_heatmap.png         # Metrics heatmap visualization
â”œâ”€â”€ per_brand_f1_radar.png               # F1-Score radar chart
â”œâ”€â”€ brand_sentiment_before_after.png      # Balance before/after comparison
â”œâ”€â”€ brand_sentiment_pie_charts.png        # Sentiment distribution pie charts
â”œâ”€â”€ brand_balance_ratio.png              # Balance ratio improvement chart
â”‚
â”œâ”€â”€ BALANCED DATASETS:
â”œâ”€â”€ kopi_nako_balanced.csv               # Balanced Kopi Nako (1,768 samples)
â”œâ”€â”€ starbucks_balanced.csv               # Balanced Starbucks (964 samples)
â”œâ”€â”€ kopi_kenangan_balanced.csv           # Balanced Kopi Kenangan (2,518 samples)
â”‚
â”œâ”€â”€ STREAMLIT APP:
â”œâ”€â”€ streamlit_app.py                     # Interactive dashboard
â”œâ”€â”€ requirements.txt                      # Python dependencies
â”‚
â””â”€â”€ README.md                             # This file
```

---

## ğŸš€ Installation & Setup

### Prerequisites
- Python 3.11 or higher
- Windows, Linux, or macOS
- 4GB RAM minimum

### Step 1: Clone or Download Repository
```bash
cd d:\skripsi angel
```

### Step 2: Create Virtual Environment
```bash
python -m venv venv
```

### Step 3: Activate Virtual Environment
```bash
# Windows
.\venv\Scripts\Activate.ps1

# Linux/macOS
source venv/bin/activate
```

### Step 4: Install Dependencies
```bash
pip install --trusted-host pypi.python.org --trusted-host files.pythonhosted.org pandas numpy matplotlib seaborn scikit-learn nltk openpyxl
```

---

## ğŸ’» Usage

### Run Full Analysis
```bash
python sentiment_analysis.py
```

### Expected Output
The script will:
1. Load both CSV datasets
2. Clean and preprocess text data
3. Extract TF-IDF features
4. Train 6 machine learning models
5. Evaluate each model with comprehensive metrics
6. Generate visualizations and reports
7. Save results to CSV and PNG files

### Runtime
- Estimated execution time: **2-3 minutes** (depending on machine specs)
- Generates 6 output files

---

## ğŸ“ˆ Model Performance

### ğŸ† Overall Rankings (Combined Dataset: 1,583 reviews)

<div align="center">

| Rank | ğŸ¥‡ Model | Accuracy | Precision | Recall | F1-Score | AUC-ROC |
|:----:|:---------|:--------:|:---------:|:------:|:--------:|:-------:|
| ğŸ¥‡ | **Decision Tree** | **88.96%** | **87.56%** | **88.96%** | **86.94%** | 70.84% |
| ğŸ¥ˆ | Gradient Boosting | 88.64% | 87.22% | 88.64% | 86.18% | **81.67%** |
| ğŸ¥‰ | Support Vector Machine | 87.70% | 86.26% | 87.70% | 83.84% | **90.46%** â­ |
| 4ï¸âƒ£ | Multinomial Naive Bayes | 87.70% | 87.18% | 87.70% | 83.44% | 83.88% |
| 5ï¸âƒ£ | Logistic Regression | 86.75% | 83.49% | 86.75% | 81.94% | 88.65% |
| 6ï¸âƒ£ | Random Forest | 86.44% | 74.71% | 86.44% | 80.15% | 85.67% |

</div>

### ğŸ“Š Best Models Explained

**ğŸ† Best Overall: Decision Tree (88.96% Accuracy)**
```
âœ“ Highest accuracy and F1-score
âœ“ Balanced performance across metrics
âœ“ Fast inference time
âœ“ Interpretable results
```

**â­ Best AUC-ROC: Support Vector Machine (90.46%)**
```
âœ“ Excellent class discrimination
âœ“ Most reliable probability estimates
âœ“ Best for ranking predictions
âœ“ Superior generalization
```

---

## â˜• Per-Brand Analysis & Metrics

### ğŸ¯ Per-Brand Model Performance

<details>
<summary><b>KOPI NAKO</b> (1,768 balanced samples) - Click to expand</summary>

| Model | Accuracy | Precision | Recall | F1-Score | AUC-ROC |
|-------|----------|-----------|--------|----------|---------|
| ğŸ¥‡ **SVM** | **97.74%** | **97.84%** | **97.74%** | **97.74%** | **99.99%** |
| Random Forest | 97.46% | 97.58% | 97.46% | 97.46% | 99.98% |
| Logistic Regression | 95.48% | 95.53% | 95.48% | 95.48% | 99.95% |
| Gradient Boosting | 92.94% | 93.81% | 92.94% | 92.90% | 99.77% |
| Decision Tree | 92.66% | 93.60% | 92.66% | 92.62% | 99.65% |
| Naive Bayes | 91.53% | 92.30% | 91.53% | 91.49% | 99.45% |

**âœ¨ Best Model: SVM (97.74% F1-Score)**

</details>

<details>
<summary><b>STARBUCKS</b> (964 balanced samples) - Click to expand</summary>

| Model | Accuracy | Precision | Recall | F1-Score | AUC-ROC |
|-------|----------|-----------|--------|----------|---------|
| ğŸ¥‡ **Gradient Boosting** | **95.34%** | **95.38%** | **95.34%** | **95.34%** | **99.88%** |
| Logistic Regression | 91.71% | 91.71% | 91.71% | 91.71% | 99.65% |
| SVM | 91.71% | 91.71% | 91.71% | 91.71% | 99.62% |
| Random Forest | 90.67% | 90.96% | 90.67% | 90.66% | 99.58% |
| Naive Bayes | 87.56% | 87.98% | 87.56% | 87.53% | 99.12% |
| Decision Tree | 78.24% | 84.81% | 78.24% | 77.13% | 98.15% |

**âœ¨ Best Model: Gradient Boosting (95.34% F1-Score)**

</details>

<details>
<summary><b>KOPI KENANGAN</b> (2,518 balanced samples) - Click to expand</summary>

| Model | Accuracy | Precision | Recall | F1-Score | AUC-ROC |
|-------|----------|-----------|--------|----------|---------|
| ğŸ¥‡ **SVM** | **96.43%** | **96.44%** | **96.43%** | **96.43%** | **99.99%** |
| Logistic Regression | 95.24% | 95.31% | 95.24% | 95.24% | 99.96% |
| Gradient Boosting | 94.84% | 94.84% | 94.84% | 94.84% | 99.91% |
| Random Forest | 94.44% | 94.58% | 94.44% | 94.44% | 99.89% |
| Decision Tree | 92.66% | 92.90% | 92.66% | 92.65% | 99.69% |
| Naive Bayes | 89.88% | 90.06% | 89.88% | 89.87% | 99.24% |

**âœ¨ Best Model: SVM (96.43% F1-Score)**

</details>

### ğŸ–ï¸ Brand Rankings

<div align="center">

| Rank | Brand | Best F1-Score | Best Model | Status |
|:----:|:------|:-------------:|:-----------|:-------|
| ğŸ¥‡ | **Kopi Nako** | **97.74%** | SVM | ğŸŸ¢ EXCELLENT |
| ğŸ¥ˆ | **Kopi Kenangan** | **96.43%** | SVM | ğŸŸ¢ EXCELLENT |
| ğŸ¥‰ | **Starbucks** | **95.34%** | Gradient Boosting | ğŸŸ¢ VERY GOOD |

</div>

### ğŸ“Š Per-Brand Visualization Files

**ğŸ“ˆ Metrics Visualizations:**
- `per_brand_metrics_comparison.png` - ğŸ“Š Accuracy, Precision, Recall, F1 comparison
- `per_brand_metrics_heatmap.png` - ğŸ”¥ Heatmap of all metrics per brand
- `per_brand_models_comparison.png` - ğŸ“Š All 6 models performance per brand
- `per_brand_f1_radar.png` - ğŸ¯ Radar chart of F1-Scores across brands

**âš–ï¸ Balance Visualizations:**
- `brand_sentiment_before_balancing.png` - ğŸ“Š Original imbalanced distribution
- `brand_sentiment_before_after.png` - ğŸ”„ Before/after balancing comparison
- `brand_sentiment_pie_charts.png` - ğŸ¥§ Pie charts of sentiment per brand
- `brand_balance_ratio.png` - ğŸ“ˆ Balance improvement metrics

---

## ğŸ” Key Findings

### 1ï¸âƒ£ Confusion Matrix Analysis (Best Model: Decision Tree)
```
                Predicted Negative    Predicted Positive
Actual Negative:    13 (TN)              30 (FP)
Actual Positive:     5 (FN)             269 (TP)
```

**Interpretation:**
- True Positive Rate (TPR/Recall): 98.2% - Excellent at detecting positive reviews
- True Negative Rate (TNR): 30.2% - Moderate at detecting negative reviews
- False Positive Rate: 69.8% - Sometimes misclassifies negative as positive

### 2ï¸âƒ£ Sentiment Distribution
- **High Imbalance**: 86.3% positive vs 13.7% negative
- **Implication**: Models are biased toward positive sentiment
- **Recommendation**: Consider balanced sampling or class weights for production

### 3ï¸âƒ£ Top Features for Sentiment Classification

**Words Most Associated with POSITIVE Sentiment:**
- ğŸŸ¢ **enak** (delicious)
- ğŸŸ¢ **juara** (champion/excellent)
- ğŸŸ¢ **baik** (good)
- ğŸŸ¢ **nyaman** (comfortable)
- ğŸŸ¢ **ramah** (friendly)

**Words Most Associated with NEGATIVE Sentiment:**
- ğŸ”´ **ramai** (crowded)
- ğŸ”´ **lama** (slow/long)
- ğŸ”´ **bau** (smell)
- ğŸ”´ **pengap** (stuffy)
- ğŸ”´ **mahal** (expensive)

### 4ï¸âƒ£ Text Preprocessing Impact
- âœ¨ Removed special characters and numbers
- âœ¨ Converted to lowercase
- âœ¨ Applied Indonesian stopword removal
- âœ¨ Extracted 1,800 TF-IDF features

---

## ğŸ“Š Evaluation Metrics Explained

<div align="center">

| Metric | Formula | Best Range | What It Measures |
|--------|---------|-----------|------------------|
| **Accuracy** | (TP+TN)/(TP+TN+FP+FN) | 0-1 | Overall correctness |
| **Precision** | TP/(TP+FP) | 0-1 | Positive prediction accuracy |
| **Recall** | TP/(TP+FN) | 0-1 | Positive identification rate |
| **F1-Score** | 2Ã—(PrecisionÃ—Recall)/(Precision+Recall) | 0-1 | Balance of precision & recall |
| **AUC-ROC** | Area under ROC curve | 0-1 | Class discrimination ability |

</div>

### ğŸ“– Detailed Explanations

#### ğŸ¯ Accuracy
```
What: Percentage of correct predictions overall
Formula: (TP + TN) / (TP + TN + FP + FN)
Best Value: 100% (unrealistic)
Our Best: 88.96% (Decision Tree)
Meaning: Out of 100 predictions, ~89 are correct
Use: General performance overview
âš ï¸ Note: Not ideal for imbalanced datasets
```

#### ğŸ¯ Precision  
```
What: Accuracy of positive predictions
Formula: TP / (TP + FP)
Best Value: 100%
Our Best: 87.56% (Decision Tree)
Meaning: When model says "positive", it's right 87.56% of the time
Use: When false positives are costly
```

#### ğŸ¯ Recall (Sensitivity)
```
What: Percentage of actual positives identified
Formula: TP / (TP + FN)
Best Value: 100%
Our Best: 88.96% (Decision Tree)
Meaning: Model catches 88.96% of actual positive reviews
Use: When missing positives is costly
```

#### ğŸ¯ F1-Score
```
What: Harmonic mean of Precision and Recall
Formula: 2 Ã— (Precision Ã— Recall) / (Precision + Recall)
Best Value: 1.0
Our Best: 0.8694 (Decision Tree)
Range: 0 to 1
Use: BEST for imbalanced datasets (our case!)
```

#### ğŸ¯ AUC-ROC
```
What: Model's ability to distinguish between classes
Range: 0.5 (random) to 1.0 (perfect)
Our Best: 0.9046 (Support Vector Machine)
Meaning: 90.46% probability of correctly ranking
         a positive review higher than negative
Use: Best for probability-based predictions
```

### ğŸ”¢ Confusion Matrix Explained

```
                  Predicted Negative    Predicted Positive
Actual Negative:       TN                      FP
Actual Positive:       FN                      TP

TP (True Positive):      Correctly predicted positive âœ“
TN (True Negative):      Correctly predicted negative âœ“
FP (False Positive):     Incorrectly predicted positive âœ— (Type I Error)
FN (False Negative):     Incorrectly predicted negative âœ— (Type II Error)
```

---

## ğŸ“ Output Files

### 1. **model_performance_results.csv**
Comparison of all models across metrics:
```csv
Model,Accuracy,Precision,Recall,F1-Score,AUC-ROC
Decision Tree,0.8896,0.8756,0.8896,0.8694,0.7084
...
```

### 2. **model_comparison.png** 
3-panel visualization:
- Accuracy comparison bar chart
- All metrics comparison grouped bar chart
- Top 2 confusion matrices heatmaps

### 3. **roc_curve.png**
ROC curve for best model showing:
- True Positive Rate vs False Positive Rate
- AUC score
- Diagonal reference line (random classifier)

### 4. **sentiment_distribution.png**
2-panel distribution charts:
- Overall sentiment distribution
- Train-test split distribution

### 5. **feature_importance_rf.png**
Top 15 most important features from Random Forest model with relative importance values

### 6. **feature_importance_lr.png**
Top 15 feature coefficients from Logistic Regression:
- Red bars: Negative sentiment indicators
- Blue bars: Positive sentiment indicators

---

## ğŸ“‹ Requirements

### Python Packages
```
pandas==2.3.3
numpy==2.4.0
matplotlib==3.10.8
seaborn==0.13.2
scikit-learn==1.8.0
nltk==3.9.2
openpyxl==3.1.5
```

### System Requirements
- OS: Windows 7+, Linux, or macOS
- Python: 3.11 or higher
- RAM: 4GB minimum (8GB recommended)
- Disk Space: 500MB (including virtual environment)

---

## ğŸ”§ Technical Implementation

### Data Preprocessing Pipeline
1. **Loading**: Read CSV files using pandas
2. **Cleaning**: Remove NaN values, filter empty texts
3. **Text Normalization**: Lowercase conversion, special character removal
4. **Feature Extraction**: TF-IDF vectorization with:
   - Max features: 1,800
   - N-grams: (1, 2)
   - Min document frequency: 2
   - Max document frequency: 80%
5. **Train-Test Split**: 80-20 stratified split

### Machine Learning Models

| Model | Type | Key Parameters |
|-------|------|-----------------|
| Decision Tree | Tree-based | max_depth=15 |
| Gradient Boosting | Ensemble | n_estimators=80, max_depth=5 |
| Support Vector Machine | Kernel-based | kernel='rbf', probability=True |
| Multinomial Naive Bayes | Probabilistic | Default |
| Logistic Regression | Linear | max_iter=1000, solver='lbfgs' |
| Random Forest | Ensemble | n_estimators=80, max_depth=15 |

---

## ğŸ’¡ Recommendations

### For Production Deployment:
1. **Use Support Vector Machine** for best generalization (highest AUC-ROC: 0.9046)
2. **Implement ensemble voting** combining top 3 models for robustness
3. **Handle class imbalance** using:
   - SMOTE (Synthetic Minority Over-sampling Technique)
   - Class weights in model training
   - Stratified cross-validation
4. **Monitor model drift** - retrain monthly with new reviews

### For Model Improvement:
1. **Collect more negative examples** to balance dataset
2. **Implement deep learning** (BERT, LSTM) for better contextual understanding
3. **Add n-gram analysis** and sentiment lexicon features
4. **Apply hyperparameter tuning** (GridSearchCV, RandomizedSearchCV)
5. **Use cross-validation** instead of single train-test split

### For Business Application:
1. Use model predictions to monitor customer satisfaction
2. Identify common complaints from negative reviews
3. Track sentiment trends over time
4. Alert management when negative sentiment increases
5. Use top features to guide product/service improvements

---

## ï¿½ Deployment

### ğŸŒ Option 1: Streamlit Cloud (Recommended - FREE)

<div align="center">

**[ğŸš€ LIVE DASHBOARD](https://sentimentanalysiscoffeeshop.streamlit.app)**

</div>

#### Deploy Steps (3 minutes):
```
1ï¸âƒ£  Go to https://streamlit.io/cloud
2ï¸âƒ£  Sign in with GitHub account (SeedFlora)
3ï¸âƒ£  Click "New app"
4ï¸âƒ£  Select repository: SeedFlora/sentimentAnalysisCoffeeShop
5ï¸âƒ£  Branch: main
6ï¸âƒ£  Main file path: streamlit_app.py
7ï¸âƒ£  Click "Deploy" and wait 2-3 minutes
```

**Result:** App will be live at `https://sentimentanalysiscoffeeshop.streamlit.app`

### ğŸ’» Option 2: Run Locally

```bash
# 1. Activate environment
.\venv\Scripts\Activate.ps1

# 2. Install Streamlit
pip install streamlit

# 3. Run app
streamlit run streamlit_app.py

# 4. Open browser to http://localhost:8501
```

### ğŸ¨ Dashboard Features

```
ğŸ“Š Dashboard Utama
   â”œâ”€â”€ Overall sentiment statistics
   â”œâ”€â”€ Model performance metrics
   â”œâ”€â”€ Brand comparison charts
   â””â”€â”€ Key insights summary

ğŸ“ˆ Analisis Per Brand  
   â”œâ”€â”€ Brand selection dropdown
   â”œâ”€â”€ Sentiment distribution pie charts
   â”œâ”€â”€ Word cloud visualization
   â”œâ”€â”€ Performance metrics table
   â””â”€â”€ Model comparison

ğŸ”® Prediksi Sentimen
   â”œâ”€â”€ Real-time text input
   â”œâ”€â”€ Live sentiment prediction
   â”œâ”€â”€ Confidence score
   â””â”€â”€ Top contributing words

ğŸ“Š Perbandingan Model
   â”œâ”€â”€ All 6 models comparison
   â”œâ”€â”€ Metrics performance table
   â”œâ”€â”€ Ranking visualization
   â””â”€â”€ Best model recommendation
```

---

## ï¿½ğŸ“ Method Summary

**Dataset**: 1,583 Indonesian reviews from 2 coffee shop chains  
**Preprocessing**: Text cleaning, TF-IDF feature extraction  
**Train-Test Split**: 80% (1,266) training, 20% (317) testing  
**Models Evaluated**: 6 machine learning algorithms  
**Best Performing**: Decision Tree (88.96% accuracy, 0.8694 F1-score)  
**Highest AUC-ROC**: Support Vector Machine (0.9046)  

---

## ğŸ› Troubleshooting

### Issue: "ModuleNotFoundError: No module named 'nltk'"
```bash
pip install nltk --trusted-host pypi.python.org --trusted-host files.pythonhosted.org
```

### Issue: Matplotlib showing empty plots
The script uses non-interactive backend ('Agg'). PNG files are saved to disk automatically.

### Issue: Script running too slow
- Reduce n_estimators in Random Forest and Gradient Boosting
- Reduce max_features in TfidfVectorizer
- Check available RAM and close other applications

### Issue: "NLTK stopwords not found"
The script automatically downloads stopwords. If not working:
```python
import nltk
nltk.download('stopwords')
```

---

## ğŸ“ Educational Value

This project demonstrates:
- âœ… **Data Preprocessing**: Text cleaning and normalization
- âœ… **Feature Engineering**: TF-IDF vectorization
- âœ… **Machine Learning**: 6 different algorithms
- âœ… **Model Evaluation**: Comprehensive metrics and visualization
- âœ… **Statistical Analysis**: Confusion matrices and ROC curves
- âœ… **NLP Basics**: Indonesian text processing and stopword removal
- âœ… **Software Engineering**: Virtual environments and dependency management

---

## ğŸ“š References

### Papers & Concepts
- TF-IDF: Salton, G., & McGill, M. (1983). Introduction to Modern Information Retrieval.
- ROC Curves: Hanley, J. A., & McNeil, B. J. (1982). The meaning of area under a ROC curve.
- Confusion Matrix: Powers, D. M. (2011). Evaluation: From Precision, Recall and F-Measure to ROC, Informedness, Markedness and Correlation.

### Python Libraries
- [Scikit-learn Documentation](https://scikit-learn.org/)
- [Pandas Documentation](https://pandas.pydata.org/)
- [NLTK Documentation](https://www.nltk.org/)
- [Matplotlib Documentation](https://matplotlib.org/)

---

## âœ¨ Future Enhancements

- [ ] Implement deep learning models (BERT, LSTM, GRU)
- [ ] Add aspect-based sentiment analysis (taste, service, ambience)
- [ ] Implement active learning for efficient data labeling
- [ ] Create REST API for real-time predictions
- [ ] Add multi-language support (English, Indonesian variants)
- [ ] Implement sentiment intensity prediction (not just binary)
- [ ] Deploy as web application (Flask/Streamlit)
- [ ] Add comparative analysis between chains

---

---

## ğŸ“Š Quick Stats

<div align="center">

```
ğŸ† MODEL PERFORMANCE SUMMARY
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
  Best Accuracy:    88.96% (Decision Tree)
  Best AUC-ROC:     90.46% (SVM)
  Best F1-Score:    86.94% (Decision Tree)
  
ğŸ“Š DATASET STATISTICS
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
  Total Reviews:    3,034
  Positive Reviews: 2,615 (86%)
  Negative Reviews:   419 (14%)
  Features (TF-IDF): 1,800
  
â±ï¸ PERFORMANCE METRICS
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
  Training Time:    ~2-3 minutes
  Inference Time:   <1 second per review
  Model Size:       ~5-50 MB each
```

</div>

---

## ğŸ‘¥ Contact & Support

<div align="center">

| Area | Details |
|------|---------|
| ğŸ“§ **Email** | juartobudi@gmail.com |
| ğŸ™ **GitHub** | [@SeedFlora](https://github.com/SeedFlora) |
| ğŸ”— **Repository** | [sentimentAnalysisCoffeeShop](https://github.com/SeedFlora/sentimentAnalysisCoffeeShop) |
| ğŸš€ **Live App** | [Streamlit Dashboard](https://sentimentanalysiscoffeeshop.streamlit.app) |

</div>

### ğŸ“ Troubleshooting

<details>
<summary><b>Common Issues & Solutions</b> - Click to expand</summary>

#### âŒ ModuleNotFoundError
```bash
pip install nltk --trusted-host pypi.python.org
```

#### âŒ Matplotlib showing empty plots
Script uses non-interactive backend ('Agg'). PNG files saved automatically.

#### âŒ Script running too slow
- Reduce n_estimators in models
- Close other applications
- Check available RAM (4GB minimum)

#### âŒ NLTK stopwords not found
```python
import nltk
nltk.download('stopwords')
```

</details>

---

## ğŸ™ Acknowledgments

- â˜• **Kopi Nako** - Reviews dataset
- â˜• **Starbucks** - Reviews dataset  
- â˜• **Kopi Kenangan** - Reviews dataset
- ğŸ‡®ğŸ‡© Indonesian NLP community - Stopword resources
- ğŸ“¦ Scikit-learn team - Excellent ML library
- ğŸ¨ Streamlit team - Dashboard framework

---

## ğŸ“„ License

<div align="center">

**MIT License**

Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files.

[See LICENSE file for details](LICENSE)

</div>

---

## ğŸ“ˆ Project Stats

<div align="center">

![GitHub Repo Size](https://img.shields.io/github/repo-size/SeedFlora/sentimentAnalysisCoffeeShop?style=flat-square)
![GitHub Stars](https://img.shields.io/github/stars/SeedFlora/sentimentAnalysisCoffeeShop?style=flat-square)
![GitHub Forks](https://img.shields.io/github/forks/SeedFlora/sentimentAnalysisCoffeeShop?style=flat-square)
![Last Commit](https://img.shields.io/github/last-commit/SeedFlora/sentimentAnalysisCoffeeShop?style=flat-square)

**Status**: âœ… Active & Maintained  
**Last Updated**: January 6, 2026  
**Version**: 1.0.0

</div>

---

<div align="center">

### ğŸŒŸ If you find this helpful, please consider giving it a star! â­

Made with â¤ï¸ by Angel Donut Research Team

**Professional-grade machine learning implementation with comprehensive evaluation and production-ready dashboard.**

</div>
